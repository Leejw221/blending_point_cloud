1) Femto bolt frame 표현 과정
- Femto bolt로 책상 위에 있는 체커보드를 캘리브레이션 하여 변환행렬을 구한다. (femto bolt -> checkerboard)
- 체커보드에서 base로 가는 행렬을 측정하여 만든다. (checkerboard -> base)
- depth를 기준으로 point cloud로 표현하므로 depth에서 color로 가는 변환행렬을 sdk를 통해 구한다. (depth -> color)
- 이를 합쳐서 depth -> color(femto bolt) -> checkerboard -> base를 통해 depth -> base를 구한다.
-> 그 친구는 depth를 통해 point cloud로 표현한걸로 기억해. 아마 depth가 더 작은 해상도로 해서 그런거 같아.

2) D405 frame 표현 과정
- base에서 로봇팔 base의 변환행려를 측정하여 구한다. (base -> robot arm base)
- robot arm base에서 FK를 통해 end-effector까지의 변환행렬을 구한다. (robot arm base -> end-effector)
- end-effector에서 D405까지 변환행렬을 측정하여 구한다. 이는 inventor 도면상에서 측정하였지만 살짝 오차는 있을 수 있다. (end-effector -> D405)
- 이를 통해 base -> robot arm base -> end-effector -> D405를 계산하여 base -> D405를 구한다.

위 과정을 통해 D405와 Femto bolt에서 표현한 point cloud를 base 기준으로 표현한다.
-> 참고로 PCDP에서는 D405를 사용하지 않는다. 하지만 end-effector 위치는 로봇팔을 사용하기 위해서 사용한다.

# 검증 단계
1. PCDP 방식 적용하여 point_cloud_femto_bolt.py를 수정하여 표현한다.
2. 같은 뷰에 대하여 orbbecviewer랑 python을 통해 point 값 비교하기
-> 이를 통해 point cloud가 제대로 표현되었는지 확인
3. point_cloud_d405.py를  검토하여 수정한다.
4. 2번과 같은 방식으로 검증한다. 4번까지 하였으면 femto bolt와 d405에 대한 point cloud를 정상적이라고 판단
5. double_view_point_cloud.py를 만들어서 두 카메라에 대한 point cloud 표현하기 
-> 이때, 좌표계를 같이 표현한다.
-> 표현하는 좌표계는 base, femto bolt, d405, robot arm base, end-effector만 표현한다.
-> end-effector와 d405는 로봇팔이 움직임에 따라 변화하는 dynamic frame이어야 한다.
6. 같은 물체에 대해서 base 표현된 femto bolt와 d405에 대한 point 값이 유사한지 검증
7. 6번까지의 과정을 기반으로 single_point_cloud.py로 blending 작업 시작하기.
